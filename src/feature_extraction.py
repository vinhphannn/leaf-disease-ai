#!/usr/bin/env python3
"""
Feature extraction and visualization for leaf disease classification
"""

import torch
import torch.nn.functional as F
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from typing import List, Tuple, Dict
import os

class FeatureExtractor:
    """Extract and visualize features that the model focuses on"""
    
    def __init__(self, model, target_layer_name="backbone.blocks.6.0"):
        self.model = model
        self.target_layer = None
        self.gradients = None
        self.activations = None
        
        # Register hooks
        self._register_hooks(target_layer_name)
    
    def _register_hooks(self, layer_name):
        """Register forward and backward hooks"""
        def forward_hook(module, input, output):
            self.activations = output
        
        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0]
            return None
        
        # Find the target layer
        for name, module in self.model.named_modules():
            if name == layer_name:
                self.target_layer = module
                break
        
        if self.target_layer is not None:
            self.target_layer.register_forward_hook(forward_hook)
            self.target_layer.register_full_backward_hook(backward_hook)
    
    def generate_gradcam(self, image_tensor, class_idx=None):
        """Generate Grad-CAM heatmap"""
        # Forward pass
        self.model.eval()
        image_tensor.requires_grad_(True)
        
        # Forward pass
        output = self.model(image_tensor)
        
        if class_idx is None:
            class_idx = output.argmax(dim=1)
        
        # Backward pass
        self.model.zero_grad()
        output[0, class_idx].backward()
        
        # Generate Grad-CAM
        gradients = self.gradients[0].cpu().data.numpy()
        activations = self.activations[0].cpu().data.numpy()
        
        # Global average pooling of gradients
        weights = np.mean(gradients, axis=(1, 2))
        
        # Weighted combination of activation maps
        cam = np.zeros(activations.shape[1:], dtype=np.float32)
        for i, w in enumerate(weights):
            cam += w * activations[i, :, :]
        
        # Normalize
        cam = np.maximum(cam, 0)
        cam = cam / cam.max() if cam.max() > 0 else cam
        
        return cam
    
    def analyze_heatmap_regions(self, heatmap, image_size=(224, 224)):
        """Analyze heatmap to extract meaningful features"""
        # Resize heatmap to image size
        heatmap_resized = cv2.resize(heatmap, image_size)
        
        # Threshold to get significant regions
        threshold = 0.3
        significant_regions = heatmap_resized > threshold
        
        # Find contours
        contours, _ = cv2.findContours(
            (significant_regions * 255).astype(np.uint8), 
            cv2.RETR_EXTERNAL, 
            cv2.CHAIN_APPROX_SIMPLE
        )
        
        # Analyze regions
        regions_info = []
        for contour in contours:
            if cv2.contourArea(contour) > 100:  # Filter small regions
                # Get bounding box
                x, y, w, h = cv2.boundingRect(contour)
                
                # Calculate region properties
                area = cv2.contourArea(contour)
                center_x = x + w // 2
                center_y = y + h // 2
                
                # Position relative to image
                rel_x = center_x / image_size[0]
                rel_y = center_y / image_size[1]
                
                regions_info.append({
                    'bbox': (x, y, w, h),
                    'area': area,
                    'center': (center_x, center_y),
                    'relative_position': (rel_x, rel_y),
                    'intensity': np.mean(heatmap_resized[y:y+h, x:x+w])
                })
        
        return regions_info
    
    def generate_natural_language_explanation(self, class_name, confidence, regions_info, heatmap):
        """Generate natural language explanation"""
        explanations = []
        
        # Basic prediction
        explanations.append(f"üå± **D·ª± ƒëo√°n**: {class_name.replace('___', ' - ')}")
        explanations.append(f"üéØ **ƒê·ªô tin c·∫≠y**: {confidence:.1%}")
        
        # Analyze regions
        if regions_info:
            explanations.append("\nüîç **Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng:**")
            
            # Sort regions by intensity
            regions_info.sort(key=lambda x: x['intensity'], reverse=True)
            
            for i, region in enumerate(regions_info[:3]):  # Top 3 regions
                rel_x, rel_y = region['relative_position']
                intensity = region['intensity']
                
                # Position description
                if rel_x < 0.3:
                    pos_x = "b√™n tr√°i"
                elif rel_x > 0.7:
                    pos_x = "b√™n ph·∫£i"
                else:
                    pos_x = "gi·ªØa"
                
                if rel_y < 0.3:
                    pos_y = "ph·∫ßn tr√™n"
                elif rel_y > 0.7:
                    pos_y = "ph·∫ßn d∆∞·ªõi"
                else:
                    pos_y = "ph·∫ßn gi·ªØa"
                
                # Intensity description
                if intensity > 0.7:
                    intensity_desc = "r·∫•t m·∫°nh"
                elif intensity > 0.5:
                    intensity_desc = "m·∫°nh"
                elif intensity > 0.3:
                    intensity_desc = "trung b√¨nh"
                else:
                    intensity_desc = "y·∫øu"
                
                # Detailed region analysis
                region_desc = f"   {i+1}. **V√πng {pos_x} {pos_y}** c·ªßa l√° c√≥ t√≠n hi·ªáu {intensity_desc} "
                region_desc += f"(c∆∞·ªùng ƒë·ªô: {intensity:.2f})"
                
                # Add specific analysis based on position and intensity
                if intensity > 0.7:
                    region_desc += " - M√¥ h√¨nh r·∫•t ch√∫ √Ω ƒë·∫øn v√πng n√†y"
                elif intensity > 0.5:
                    region_desc += " - M√¥ h√¨nh ch√∫ √Ω v·ª´a ph·∫£i ƒë·∫øn v√πng n√†y"
                else:
                    region_desc += " - M√¥ h√¨nh √≠t ch√∫ √Ω ƒë·∫øn v√πng n√†y"
                
                # Add position-specific insights
                if rel_x < 0.3 and rel_y < 0.3:
                    region_desc += " (g√≥c tr√™n tr√°i)"
                elif rel_x > 0.7 and rel_y < 0.3:
                    region_desc += " (g√≥c tr√™n ph·∫£i)"
                elif rel_x < 0.3 and rel_y > 0.7:
                    region_desc += " (g√≥c d∆∞·ªõi tr√°i)"
                elif rel_x > 0.7 and rel_y > 0.7:
                    region_desc += " (g√≥c d∆∞·ªõi ph·∫£i)"
                elif 0.3 <= rel_x <= 0.7 and 0.3 <= rel_y <= 0.7:
                    region_desc += " (trung t√¢m l√°)"
                
                explanations.append(region_desc)
        else:
            explanations.append("\nüîç **Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng:**")
            explanations.append("   M√¥ h√¨nh t·∫≠p trung v√†o to√†n b·ªô l√° m·ªôt c√°ch ƒë·ªìng ƒë·ªÅu")
        
        # Disease-specific explanations
        disease_explanations = self._get_disease_specific_explanations(class_name)
        if disease_explanations:
            explanations.append(f"\nüìã **M√¥ t·∫£ b·ªánh:**")
            explanations.extend(disease_explanations)
        
        return "\n".join(explanations)
    
    def _get_disease_specific_explanations(self, class_name):
        """Get disease-specific explanations"""
        explanations = {
            'Apple___Apple_scab': [
                "‚Ä¢ **B·ªánh gh·∫ª t√°o (Apple Scab)**: B·ªánh n·∫•m ph·ªï bi·∫øn nh·∫•t tr√™n c√¢y t√°o",
                "‚Ä¢ **Tri·ªáu ch·ª©ng**: C√°c ƒë·ªëm ƒëen nh·ªè, tr√≤n, c√≥ vi·ªÅn r√µ r√†ng tr√™n l√°",
                "‚Ä¢ **V·ªã tr√≠**: Th∆∞·ªùng b·∫Øt ƒë·∫ßu t·ª´ m·∫∑t d∆∞·ªõi l√°, sau ƒë√≥ lan ra m·∫∑t tr√™n",
                "‚Ä¢ **Ti·∫øn tri·ªÉn**: L√° b·ªã v√†ng, kh√¥ v√† r·ª•ng s·ªõm, ·∫£nh h∆∞·ªüng ƒë·∫øn nƒÉng su·∫•t",
                "‚Ä¢ **ƒêi·ªÅu ki·ªán**: Ph√°t tri·ªÉn m·∫°nh trong th·ªùi ti·∫øt ·∫©m ∆∞·ªõt, m∆∞a nhi·ªÅu"
            ],
            'Apple___Black_rot': [
                "‚Ä¢ **B·ªánh th·ªëi ƒëen (Black Rot)**: B·ªánh n·∫•m nghi√™m tr·ªçng tr√™n c√¢y t√°o",
                "‚Ä¢ **Tri·ªáu ch·ª©ng**: C√°c ƒë·ªëm n√¢u ƒëen l·ªõn, kh√¥ng ƒë·ªÅu, c√≥ h√¨nh tr√≤n",
                "‚Ä¢ **ƒê·∫∑c ƒëi·ªÉm**: Vi·ªÅn r√µ r√†ng, trung t√¢m c√≥ th·ªÉ b·ªã kh√¥ v√† n·ª©t",
                "‚Ä¢ **·∫¢nh h∆∞·ªüng**: L√° b·ªã kh√¥, cong, ·∫£nh h∆∞·ªüng ƒë·∫øn qu√° tr√¨nh quang h·ª£p",
                "‚Ä¢ **Ph√≤ng ng·ª´a**: C·∫ßn c·∫Øt t·ªâa c√†nh b·ªánh, phun thu·ªëc ph√≤ng ng·ª´a"
            ],
            'Apple___Cedar_apple_rust': [
                "‚Ä¢ **B·ªánh g·ªâ s·∫Øt t√°o (Cedar Apple Rust)**: B·ªánh n·∫•m ph·ª©c t·∫°p, c·∫ßn 2 v·∫≠t ch·ªß",
                "‚Ä¢ **Tri·ªáu ch·ª©ng**: C√°c ƒë·ªëm cam ƒë·ªè nh·ªè, c√≥ th·ªÉ c√≥ vi·ªÅn v√†ng",
                "‚Ä¢ **ƒê·∫∑c ƒëi·ªÉm**: Th∆∞·ªùng xu·∫•t hi·ªán th√†nh c·ª•m, c√≥ th·ªÉ lan r·ªông",
                "‚Ä¢ **V√≤ng ƒë·ªùi**: C·∫ßn c√¢y b√°ch x√π (cedar) v√† c√¢y t√°o ƒë·ªÉ ho√†n th√†nh chu tr√¨nh",
                "‚Ä¢ **Ph√≤ng ng·ª´a**: Tr√°nh tr·ªìng t√°o g·∫ßn c√¢y b√°ch x√π, phun thu·ªëc v√†o m√πa xu√¢n"
            ],
            'Tomato___Late_blight': [
                "‚Ä¢ B·ªánh m·ªëc s∆∞∆°ng: ƒê·ªëm n√¢u ƒëen, lan nhanh",
                "‚Ä¢ Th∆∞·ªùng xu·∫•t hi·ªán ·ªü m√©p l√° tr∆∞·ªõc",
                "‚Ä¢ L√° c√≥ th·ªÉ b·ªã h√©o v√† ch·∫øt"
            ],
            'Tomato___Early_blight': [
                "‚Ä¢ B·ªánh ƒë·ªëm s·ªõm: ƒê·ªëm n√¢u v·ªõi v√≤ng tr√≤n ƒë·ªìng t√¢m",
                "‚Ä¢ Th∆∞·ªùng b·∫Øt ƒë·∫ßu t·ª´ l√° gi√†",
                "‚Ä¢ C√≥ th·ªÉ lan ra to√†n b·ªô c√¢y"
            ],
            'Potato___Late_blight': [
                "‚Ä¢ B·ªánh m·ªëc s∆∞∆°ng khoai t√¢y: ƒê·ªëm n√¢u ƒëen l·ªõn",
                "‚Ä¢ Th∆∞·ªùng lan nhanh trong ƒëi·ªÅu ki·ªán ·∫©m ∆∞·ªõt",
                "‚Ä¢ C√≥ th·ªÉ g√¢y ch·∫øt to√†n b·ªô c√¢y"
            ],
            'Corn___Common_rust': [
                "‚Ä¢ B·ªánh g·ªâ s·∫Øt ng√¥: C√°c ƒë·ªëm cam ƒë·ªè nh·ªè",
                "‚Ä¢ Th∆∞·ªùng xu·∫•t hi·ªán th√†nh c·ª•m",
                "‚Ä¢ C√≥ th·ªÉ lan ra to√†n b·ªô l√°"
            ]
        }
        
        return explanations.get(class_name, [
            "‚Ä¢ M√¥ h√¨nh ƒë√£ ph√°t hi·ªán c√°c d·∫•u hi·ªáu b·ªánh ƒë·∫∑c tr∆∞ng",
            "‚Ä¢ Khuy·∫øn ngh·ªã ki·ªÉm tra th√™m ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c",
            "‚Ä¢ N√™n tham kh·∫£o chuy√™n gia n√¥ng nghi·ªáp n·∫øu c·∫ßn"
        ])
    
    def visualize_heatmap(self, image, heatmap, save_path=None):
        """Visualize heatmap overlay on image"""
        # Convert PIL to numpy
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # Resize heatmap to image size
        heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
        
        # Create colormap
        colormap = cm.get_cmap('jet')
        heatmap_colored = colormap(heatmap_resized)[:, :, :3]
        heatmap_colored = (heatmap_colored * 255).astype(np.uint8)
        
        # Overlay
        overlay = cv2.addWeighted(image, 0.6, heatmap_colored, 0.4, 0)
        
        # Create figure
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # Original image
        axes[0].imshow(image)
        axes[0].set_title('·∫¢nh g·ªëc')
        axes[0].axis('off')
        
        # Heatmap
        im1 = axes[1].imshow(heatmap_resized, cmap='jet')
        axes[1].set_title('Grad-CAM Heatmap')
        axes[1].axis('off')
        plt.colorbar(im1, ax=axes[1])
        
        # Overlay
        axes[2].imshow(overlay)
        axes[2].set_title('K·∫øt h·ª£p')
        axes[2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
        
        return fig

def extract_features_and_explain(model, image, class_names, device='cpu'):
    """Main function to extract features and generate explanations"""
    extractor = FeatureExtractor(model)
    
    # Preprocess image
    if isinstance(image, Image.Image):
        image_tensor = preprocess_image(image)
    else:
        image_tensor = image
    
    # Get prediction
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = F.softmax(output, dim=1)
        predicted_class_idx = output.argmax(dim=1).item()
        confidence = probabilities[0, predicted_class_idx].item()
        predicted_class = class_names[predicted_class_idx]
    
    # Generate Grad-CAM
    heatmap = extractor.generate_gradcam(image_tensor, predicted_class_idx)
    
    # Analyze regions
    regions_info = extractor.analyze_heatmap_regions(heatmap)
    
    # Generate explanation
    explanation = extractor.generate_natural_language_explanation(
        predicted_class, confidence, regions_info, heatmap
    )
    
    return {
        'predicted_class': predicted_class,
        'confidence': confidence,
        'heatmap': heatmap,
        'regions_info': regions_info,
        'explanation': explanation
    }

def preprocess_image(image, image_size=224):
    """Preprocess image for inference"""
    from torchvision import transforms
    
    transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor
